{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = '*1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xmltodict as xd\n",
    "import pandas as pd\n",
    "import os, glob\n",
    "import mio\n",
    "import numpy as np\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point, Polygon\n",
    "import pathlib\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_model(dae_file:str) -> dict:\n",
    "    \" get point and vertex list for one model\"\n",
    "    with open(dae_file) as fin:\n",
    "        s = fin.read()\n",
    "    d = xd.parse(s)\n",
    "    \n",
    "    geometries = d['COLLADA']['library_geometries']['geometry']\n",
    "    \n",
    "    res = {}\n",
    "    for geo in geometries:\n",
    "        geo_id = geo['@id']\n",
    "\n",
    "        # float list\n",
    "        f_list = geo['mesh']['source']['float_array']['#text'].split()\n",
    "        f_list = [float(f) for f in f_list]\n",
    "\n",
    "        # vertex list\n",
    "        v_list = geo['mesh']['triangles']['p'].split()\n",
    "        v_list = [int(n) for n in v_list]\n",
    "        # write result\n",
    "        \n",
    "        res[geo_id] = (f_list, v_list)\n",
    "    \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def comb_f_v(f_list, v_list):\n",
    "    va = np.array(v_list)\n",
    "    va = va.reshape(len(v_list)//3, 3)\n",
    "    v = pd.DataFrame(va, columns=['v0', 'v1', 'v2'])\n",
    "    \n",
    "    fa = np.array(f_list)\n",
    "    fa = fa.reshape(len(f_list)//3, 3)\n",
    "    f = pd.DataFrame(fa, columns=['x', 'y', 'z'])\n",
    "    \n",
    "    assert max(v.v0.max(), v.v1.max(), v.v2.max()) +1 == len(f)\n",
    "    \n",
    "    # combine the lists\n",
    "    res = (\n",
    "        v.join(f, on='v0').rename(columns={'x':'x0', 'y':'y0', 'z':'z0'})\n",
    "         .join(f, on='v1').rename(columns={'x':'x1', 'y':'y1', 'z':'z1'})\n",
    "         .join(f, on='v2').rename(columns={'x':'x2', 'y':'y2', 'z':'z2'})\n",
    "         .drop(columns=['v0', 'v1', 'v2'])\n",
    "    )\n",
    "    \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dae2df(dae_path):\n",
    "    dae_path = pathlib.Path(dae_path)\n",
    "    dic = parse_model(dae_path)\n",
    "    ldf = []\n",
    "    for key in dic:\n",
    "        f_list, v_list = dic[key]\n",
    "        df = comb_f_v(f_list, v_list)\n",
    "        ldf.append(df)\n",
    "    \n",
    "    res = pd.concat(ldf)\n",
    "    res.insert(0, 'model', dae_path.name)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_list(kml_path:str)->pd.DataFrame:\n",
    "    \" read kml file, get path and anchor coordinates for every model\"\n",
    "    with open(kml_path) as fin:\n",
    "        s = fin.read()\n",
    "    kmld =  xd.parse(s)\n",
    "    rows = []\n",
    "    for pm in kmld['kml']['Document']['Placemark'][0:]:\n",
    "        model = pm['Model']\n",
    "        row = {}\n",
    "        row['model'] = os.path.basename(model['Link']['href'])\n",
    "        sLon = model['Location']['longitude']\n",
    "        sLat = model['Location']['latitude']\n",
    "        row['swiss_lon'] = float(sLon)\n",
    "        row['swiss_lat'] = float(sLat)\n",
    "        row['swiss_x'], row['swiss_y'] = mio.wgs_swiss(sLon, sLat)\n",
    "        rows.append(row)\n",
    "    df = pd.DataFrame(rows)\n",
    "    \n",
    "    mdir = str(pathlib.Path(kml_path).parent / 'models')\n",
    "    res = (\n",
    "        df.assign(model_path = lambda d : mdir + '\\\\' + d.model)\n",
    "        .set_index('model')\n",
    "    )\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create datafrme with all triangles\n",
    "#\n",
    "def make_tri_tab(kml):\n",
    "    p_kml = pathlib.Path(kml)\n",
    "    mod_list = get_model_list(p_kml)\n",
    "    ldf = []\n",
    "    i = 0\n",
    "    for ind, row in mod_list.iterrows():\n",
    "        i += 1\n",
    "        mio.show_perc(i, len(mod_list), 100)\n",
    "        try:\n",
    "            tris = dae2df(row.model_path)\n",
    "            tris.insert(0, 'kml', p_kml.name)\n",
    "            tris.insert(2, 'swiss_x', row.swiss_x)\n",
    "            tris.insert(3, 'swiss_y', row.swiss_y)\n",
    "            ldf.append(tris)\n",
    "        except:\n",
    "            print(f'Problem with {row.model_path}')\n",
    "    df = pd.concat(ldf)\n",
    "\n",
    "    # create a geo dataframe\n",
    "    vec = (\n",
    "        pd.DataFrame()\n",
    "        .assign(kml = df.kml)\n",
    "        .assign(model = df.model)\n",
    "        .assign(x0 = df.x0 + df.swiss_x, y0 = df.y0 + df.swiss_y, z0 = df.z0)\n",
    "        .assign(x1 = df.x1 + df.swiss_x, y1 = df.y1 + df.swiss_y, z1 = df.z1)\n",
    "        .assign(x2 = df.x2 + df.swiss_x, y2 = df.y2 + df.swiss_y, z2 = df.z2)\n",
    "    )\n",
    "    geom = [Polygon( [(t[0], t[1]), (t[2], t[3]), (t[4], t[5])]) for t in zip(vec.x0, vec.y0, vec.x1, vec.y1, vec.x2, vec.y2)]\n",
    "    gdf = gpd.GeoDataFrame(vec, geometry=geom)\n",
    "    # filter out vertical walls\n",
    "    res = gdf[gdf.geometry.area > 0]\n",
    "    return gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tag_todo():\n",
    "    source_dir = pathlib.Path(\"../sb_KML\")\n",
    "    tags_all = set([d.stem for d in source_dir.glob(pattern)])\n",
    "\n",
    "    dest_dir = pathlib.Path('../sb_tab')\n",
    "    tags_done =  set([t.stem for t in dest_dir.glob('*.tab')])\n",
    "\n",
    "    tags_todo = tags_all.difference(tags_done)\n",
    "    l = list(tags_todo)\n",
    "    l.sort()\n",
    "    \n",
    "    if len(l) > 0:\n",
    "        print(f\"{len(l)} files to do\")\n",
    "        return l[0]\n",
    "    else:\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "796 files to do\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'1031-31'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_tag_todo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "796 files to do\n",
      "processing 1031-31\n",
      "5.91% 11.82% 17.73% 23.64% 29.55% 35.46% 41.37% 47.28% 53.19% 59.1% 65.01% 70.92% 76.83% 82.74% 88.65% 94.56% writing 1031-31.tab\n",
      "96378 rows of type MultiPolygon written to mapinfo file.\n",
      "795 files to do\n",
      "processing 1031-41\n",
      "5.84% 11.69% 17.53% 23.38% 29.22% 35.07% 40.91% Problem with ..\\sb_KML\\1031-41\\models\\model_731.dae\n",
      "46.76% 52.6% 58.45% 64.29% 70.13% 75.98% 81.82% 87.67% 93.51% 99.36% writing 1031-41.tab\n",
      "98921 rows of type MultiPolygon written to mapinfo file.\n",
      "794 files to do\n",
      "processing 1032-11\n",
      "8.1% 16.19% 24.29% 32.39% 40.49% 48.58% 56.68% 64.78% 72.87% 80.97% 89.07% 97.17% writing 1032-11.tab\n",
      "56856 rows of type MultiPolygon written to mapinfo file.\n",
      "793 files to do\n",
      "processing 1032-21\n",
      "writing 1032-21.tab\n",
      "5392 rows of type MultiPolygon written to mapinfo file.\n",
      "792 files to do\n",
      "processing 1032-31\n",
      "2.33% 4.65% 6.98% 9.31% 11.64% 13.96% 16.29% 18.62% 20.94% 23.27% 25.6% 27.93% 30.25% 32.58% 34.91% 37.24% 39.56% 41.89% 44.22% 46.54% 48.87% 51.2% 53.53% 55.85% 58.18% 60.51% 62.83% 65.16% 67.49% 69.82% 72.14% 74.47% 76.8% 79.12% 81.45% 83.78% 86.11% 88.43% 90.76% 93.09% 95.42% 97.74% writing 1032-31.tab\n",
      "229238 rows of type MultiPolygon written to mapinfo file.\n",
      "791 files to do\n",
      "processing 1032-41\n",
      "13.19% 26.39% 39.58% 52.77% 65.96% 79.16% 92.35% writing 1032-41.tab\n",
      "30742 rows of type MultiPolygon written to mapinfo file.\n",
      "790 files to do\n",
      "processing 1033-41\n",
      "12.61% 25.22% 37.83% 50.44% 63.05% 75.66% 88.27% writing 1033-41.tab\n",
      "39276 rows of type MultiPolygon written to mapinfo file.\n",
      "789 files to do\n",
      "processing 1047-41\n",
      "4.07% 8.14% 12.21% 16.27% 20.34% 24.41% 28.48% 32.55% 36.62% "
     ]
    }
   ],
   "source": [
    "# MAIN\n",
    "while(True):\n",
    "    tag = get_tag_todo()\n",
    "    if tag is not None:\n",
    "        print(f'processing {tag}')\n",
    "        kml = f\"../sb_KML/{tag}/{tag}.kml\"\n",
    "        gdf = make_tri_tab(kml)\n",
    "        print(f'writing {tag}.tab')\n",
    "        mio.write_tab(gdf, f'../sb_tab/{tag}.tab')\n",
    "    time.sleep(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
